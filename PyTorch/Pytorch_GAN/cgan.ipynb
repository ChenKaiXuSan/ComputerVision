{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"images\") # 删除文件夹\n",
    "\n",
    "# 保存生成的图片\n",
    "os.makedirs(\"images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Namespace(b1=0.5, b2=0.999, batch_size=512, channels=1, img_size=32, latent_dim=100, lr=0.0002, n_classes=10, n_cpu=8, n_epochs=1, sample_interval=400)\n"
     ]
    }
   ],
   "source": [
    "# 定义参数\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=1, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=512, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--n_classes\", type=int, default=10, help=\"number of classes for dataset\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\n",
    "opt = parser.parse_args(args=[])\n",
    "print(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "print(img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "\n",
    "        def block(in_feat, out_feat, normailize = True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normailize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim + opt.n_classes, 128, normailize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))), # Return the product of array elements over a given axis.\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, nosie, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels), nosie), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(opt.n_classes, opt.n_classes)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(opt.n_classes + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function \n",
    "adversarial_loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "from torchsummary import summary\n",
    "# summary(generator, img_shape)\n",
    "# summary(discriminator, input_size=(img_shape))\n",
    "# print(generator)\n",
    "# print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader \n",
    "# os.makedirs(\"/data/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data/\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers \n",
    "optimizers_G = torch.optim.Adam(generator.parameters(), lr = opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizers_D = torch.optim.Adam(discriminator.parameters(), lr = opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n"
   ]
  },
  {
   "source": [
    "# training \n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # adversarial ground truths\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad = False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad = False)\n",
    "\n",
    "        # configure input \n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "        # train Generator\n",
    "\n",
    "        optimizers_G.zero_grad()\n",
    "\n",
    "        # sample noise and labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "        gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size)))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizers_G.step()\n",
    "\n",
    "        # train Discriminator\n",
    "\n",
    "        optimizers_D.zero_grad()\n",
    "\n",
    "        # loss for real images\n",
    "        validity_real = discriminator(real_imgs, labels)\n",
    "        d_real_loss = adversarial_loss(validity_real, valid)\n",
    "\n",
    "        # loss for fake images \n",
    "        validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n",
    "        d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "\n",
    "        # total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizers_D.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 137,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch 0/1] [Batch 0/118] [D loss: 0.441419] [G loss: 0.981130]\n",
      "[Epoch 0/1] [Batch 1/118] [D loss: 0.220375] [G loss: 0.955597]\n",
      "[Epoch 0/1] [Batch 2/118] [D loss: 0.063530] [G loss: 0.931369]\n",
      "[Epoch 0/1] [Batch 3/118] [D loss: 0.014326] [G loss: 0.905540]\n",
      "[Epoch 0/1] [Batch 4/118] [D loss: 0.035425] [G loss: 0.890934]\n",
      "[Epoch 0/1] [Batch 5/118] [D loss: 0.013000] [G loss: 0.888509]\n",
      "[Epoch 0/1] [Batch 6/118] [D loss: 0.014019] [G loss: 0.884337]\n",
      "[Epoch 0/1] [Batch 7/118] [D loss: 0.014125] [G loss: 0.879548]\n",
      "[Epoch 0/1] [Batch 8/118] [D loss: 0.011374] [G loss: 0.865650]\n",
      "[Epoch 0/1] [Batch 9/118] [D loss: 0.012668] [G loss: 0.846047]\n",
      "[Epoch 0/1] [Batch 10/118] [D loss: 0.011982] [G loss: 0.832983]\n",
      "[Epoch 0/1] [Batch 11/118] [D loss: 0.012652] [G loss: 0.822902]\n",
      "[Epoch 0/1] [Batch 12/118] [D loss: 0.013515] [G loss: 0.807994]\n",
      "[Epoch 0/1] [Batch 13/118] [D loss: 0.014611] [G loss: 0.787151]\n",
      "[Epoch 0/1] [Batch 14/118] [D loss: 0.014854] [G loss: 0.775464]\n",
      "[Epoch 0/1] [Batch 15/118] [D loss: 0.017256] [G loss: 0.754436]\n",
      "[Epoch 0/1] [Batch 16/118] [D loss: 0.017631] [G loss: 0.740968]\n",
      "[Epoch 0/1] [Batch 17/118] [D loss: 0.018502] [G loss: 0.727952]\n",
      "[Epoch 0/1] [Batch 18/118] [D loss: 0.020513] [G loss: 0.715856]\n",
      "[Epoch 0/1] [Batch 19/118] [D loss: 0.020653] [G loss: 0.708011]\n",
      "[Epoch 0/1] [Batch 20/118] [D loss: 0.020478] [G loss: 0.709970]\n",
      "[Epoch 0/1] [Batch 21/118] [D loss: 0.019157] [G loss: 0.720523]\n",
      "[Epoch 0/1] [Batch 22/118] [D loss: 0.017493] [G loss: 0.749041]\n",
      "[Epoch 0/1] [Batch 23/118] [D loss: 0.014224] [G loss: 0.805197]\n",
      "[Epoch 0/1] [Batch 24/118] [D loss: 0.012939] [G loss: 0.852549]\n",
      "[Epoch 0/1] [Batch 25/118] [D loss: 0.011115] [G loss: 0.882803]\n",
      "[Epoch 0/1] [Batch 26/118] [D loss: 0.026750] [G loss: 1.014615]\n",
      "[Epoch 0/1] [Batch 27/118] [D loss: 0.098112] [G loss: 0.598385]\n",
      "[Epoch 0/1] [Batch 28/118] [D loss: 0.054194] [G loss: 0.904382]\n",
      "[Epoch 0/1] [Batch 29/118] [D loss: 0.044147] [G loss: 0.794051]\n",
      "[Epoch 0/1] [Batch 30/118] [D loss: 0.039061] [G loss: 0.590891]\n",
      "[Epoch 0/1] [Batch 31/118] [D loss: 0.030518] [G loss: 0.647825]\n",
      "[Epoch 0/1] [Batch 32/118] [D loss: 0.029648] [G loss: 0.890721]\n",
      "[Epoch 0/1] [Batch 33/118] [D loss: 0.025352] [G loss: 0.703699]\n",
      "[Epoch 0/1] [Batch 34/118] [D loss: 0.021967] [G loss: 0.812703]\n",
      "[Epoch 0/1] [Batch 35/118] [D loss: 0.021482] [G loss: 0.831895]\n",
      "[Epoch 0/1] [Batch 36/118] [D loss: 0.030705] [G loss: 0.702278]\n",
      "[Epoch 0/1] [Batch 37/118] [D loss: 0.122544] [G loss: 1.259941]\n",
      "[Epoch 0/1] [Batch 38/118] [D loss: 0.511343] [G loss: 0.127634]\n",
      "[Epoch 0/1] [Batch 39/118] [D loss: 0.075232] [G loss: 0.505389]\n",
      "[Epoch 0/1] [Batch 40/118] [D loss: 0.130177] [G loss: 0.709653]\n",
      "[Epoch 0/1] [Batch 41/118] [D loss: 0.109019] [G loss: 0.692553]\n",
      "[Epoch 0/1] [Batch 42/118] [D loss: 0.068183] [G loss: 0.581603]\n",
      "[Epoch 0/1] [Batch 43/118] [D loss: 0.062302] [G loss: 0.487646]\n",
      "[Epoch 0/1] [Batch 44/118] [D loss: 0.048566] [G loss: 0.550537]\n",
      "[Epoch 0/1] [Batch 45/118] [D loss: 0.035069] [G loss: 0.684333]\n",
      "[Epoch 0/1] [Batch 46/118] [D loss: 0.031624] [G loss: 0.771973]\n",
      "[Epoch 0/1] [Batch 47/118] [D loss: 0.031339] [G loss: 0.688857]\n",
      "[Epoch 0/1] [Batch 48/118] [D loss: 0.033263] [G loss: 0.728204]\n",
      "[Epoch 0/1] [Batch 49/118] [D loss: 0.037999] [G loss: 0.735198]\n",
      "[Epoch 0/1] [Batch 50/118] [D loss: 0.060355] [G loss: 0.518399]\n",
      "[Epoch 0/1] [Batch 51/118] [D loss: 0.198926] [G loss: 1.174765]\n",
      "[Epoch 0/1] [Batch 52/118] [D loss: 0.643191] [G loss: 0.056058]\n",
      "[Epoch 0/1] [Batch 53/118] [D loss: 0.134116] [G loss: 0.455174]\n",
      "[Epoch 0/1] [Batch 54/118] [D loss: 0.210256] [G loss: 0.704032]\n",
      "[Epoch 0/1] [Batch 55/118] [D loss: 0.178074] [G loss: 0.525446]\n",
      "[Epoch 0/1] [Batch 56/118] [D loss: 0.156889] [G loss: 0.353698]\n",
      "[Epoch 0/1] [Batch 57/118] [D loss: 0.162706] [G loss: 0.271195]\n",
      "[Epoch 0/1] [Batch 58/118] [D loss: 0.143476] [G loss: 0.335609]\n",
      "[Epoch 0/1] [Batch 59/118] [D loss: 0.121059] [G loss: 0.455389]\n",
      "[Epoch 0/1] [Batch 60/118] [D loss: 0.101008] [G loss: 0.502630]\n",
      "[Epoch 0/1] [Batch 61/118] [D loss: 0.088640] [G loss: 0.500420]\n",
      "[Epoch 0/1] [Batch 62/118] [D loss: 0.069347] [G loss: 0.555674]\n",
      "[Epoch 0/1] [Batch 63/118] [D loss: 0.067846] [G loss: 0.629496]\n",
      "[Epoch 0/1] [Batch 64/118] [D loss: 0.086577] [G loss: 0.413599]\n",
      "[Epoch 0/1] [Batch 65/118] [D loss: 0.314415] [G loss: 1.411975]\n",
      "[Epoch 0/1] [Batch 66/118] [D loss: 0.966946] [G loss: 0.104858]\n",
      "[Epoch 0/1] [Batch 67/118] [D loss: 0.167610] [G loss: 0.521660]\n",
      "[Epoch 0/1] [Batch 68/118] [D loss: 0.266551] [G loss: 0.819312]\n",
      "[Epoch 0/1] [Batch 69/118] [D loss: 0.212568] [G loss: 0.571844]\n",
      "[Epoch 0/1] [Batch 70/118] [D loss: 0.192087] [G loss: 0.349952]\n",
      "[Epoch 0/1] [Batch 71/118] [D loss: 0.190460] [G loss: 0.242643]\n",
      "[Epoch 0/1] [Batch 72/118] [D loss: 0.170617] [G loss: 0.287483]\n",
      "[Epoch 0/1] [Batch 73/118] [D loss: 0.140106] [G loss: 0.410697]\n",
      "[Epoch 0/1] [Batch 74/118] [D loss: 0.117866] [G loss: 0.510445]\n",
      "[Epoch 0/1] [Batch 75/118] [D loss: 0.098986] [G loss: 0.443766]\n",
      "[Epoch 0/1] [Batch 76/118] [D loss: 0.084888] [G loss: 0.564592]\n",
      "[Epoch 0/1] [Batch 77/118] [D loss: 0.079031] [G loss: 0.534238]\n",
      "[Epoch 0/1] [Batch 78/118] [D loss: 0.093262] [G loss: 0.675639]\n",
      "[Epoch 0/1] [Batch 79/118] [D loss: 0.274724] [G loss: 0.101433]\n",
      "[Epoch 0/1] [Batch 80/118] [D loss: 1.171685] [G loss: 2.630538]\n",
      "[Epoch 0/1] [Batch 81/118] [D loss: 0.526580] [G loss: 0.020176]\n",
      "[Epoch 0/1] [Batch 82/118] [D loss: 0.309859] [G loss: 0.077941]\n",
      "[Epoch 0/1] [Batch 83/118] [D loss: 0.219597] [G loss: 0.324261]\n",
      "[Epoch 0/1] [Batch 84/118] [D loss: 0.212657] [G loss: 0.482759]\n",
      "[Epoch 0/1] [Batch 85/118] [D loss: 0.180265] [G loss: 0.502064]\n",
      "[Epoch 0/1] [Batch 86/118] [D loss: 0.144069] [G loss: 0.430861]\n",
      "[Epoch 0/1] [Batch 87/118] [D loss: 0.117328] [G loss: 0.384765]\n",
      "[Epoch 0/1] [Batch 88/118] [D loss: 0.091662] [G loss: 0.475678]\n",
      "[Epoch 0/1] [Batch 89/118] [D loss: 0.073030] [G loss: 0.624065]\n",
      "[Epoch 0/1] [Batch 90/118] [D loss: 0.063219] [G loss: 0.603902]\n",
      "[Epoch 0/1] [Batch 91/118] [D loss: 0.059799] [G loss: 0.593911]\n",
      "[Epoch 0/1] [Batch 92/118] [D loss: 0.062843] [G loss: 0.719197]\n",
      "[Epoch 0/1] [Batch 93/118] [D loss: 0.129993] [G loss: 0.299380]\n",
      "[Epoch 0/1] [Batch 94/118] [D loss: 0.340926] [G loss: 1.324854]\n",
      "[Epoch 0/1] [Batch 95/118] [D loss: 0.735923] [G loss: 0.056685]\n",
      "[Epoch 0/1] [Batch 96/118] [D loss: 0.227716] [G loss: 0.544401]\n",
      "[Epoch 0/1] [Batch 97/118] [D loss: 0.287626] [G loss: 0.685983]\n",
      "[Epoch 0/1] [Batch 98/118] [D loss: 0.246528] [G loss: 0.406780]\n",
      "[Epoch 0/1] [Batch 99/118] [D loss: 0.239880] [G loss: 0.246270]\n",
      "[Epoch 0/1] [Batch 100/118] [D loss: 0.239243] [G loss: 0.230188]\n",
      "[Epoch 0/1] [Batch 101/118] [D loss: 0.219478] [G loss: 0.285112]\n",
      "[Epoch 0/1] [Batch 102/118] [D loss: 0.204126] [G loss: 0.366975]\n",
      "[Epoch 0/1] [Batch 103/118] [D loss: 0.187404] [G loss: 0.391897]\n",
      "[Epoch 0/1] [Batch 104/118] [D loss: 0.178751] [G loss: 0.364950]\n",
      "[Epoch 0/1] [Batch 105/118] [D loss: 0.158153] [G loss: 0.366289]\n",
      "[Epoch 0/1] [Batch 106/118] [D loss: 0.149639] [G loss: 0.397176]\n",
      "[Epoch 0/1] [Batch 107/118] [D loss: 0.139391] [G loss: 0.417121]\n",
      "[Epoch 0/1] [Batch 108/118] [D loss: 0.133323] [G loss: 0.429263]\n",
      "[Epoch 0/1] [Batch 109/118] [D loss: 0.124420] [G loss: 0.440562]\n",
      "[Epoch 0/1] [Batch 110/118] [D loss: 0.122010] [G loss: 0.433691]\n",
      "[Epoch 0/1] [Batch 111/118] [D loss: 0.118855] [G loss: 0.509095]\n",
      "[Epoch 0/1] [Batch 112/118] [D loss: 0.128467] [G loss: 0.337110]\n",
      "[Epoch 0/1] [Batch 113/118] [D loss: 0.163416] [G loss: 0.751554]\n",
      "[Epoch 0/1] [Batch 114/118] [D loss: 0.332821] [G loss: 0.056157]\n",
      "[Epoch 0/1] [Batch 115/118] [D loss: 0.247145] [G loss: 1.026251]\n",
      "[Epoch 0/1] [Batch 116/118] [D loss: 0.129463] [G loss: 0.398744]\n",
      "[Epoch 0/1] [Batch 117/118] [D loss: 0.147492] [G loss: 0.277046]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2, 4, 5],\n        [4, 3, 2, 9]])\nEmbedding(10, 3)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "input = torch.LongTensor([[1,2,4, 5], [4, 3, 2, 9]])\n",
    "print(input)\n",
    "embedding = nn.Embedding(10, 3)\n",
    "print(embedding)\n",
    "embedding(input).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([20, 100])\ntorch.Size([20, 100])\n"
     ]
    }
   ],
   "source": [
    "m = nn.BatchNorm1d(100)\n",
    "input = torch.randn(20, 100)\n",
    "print(input.shape)\n",
    "output = m(input)\n",
    "print(output.shape)"
   ]
  }
 ]
}